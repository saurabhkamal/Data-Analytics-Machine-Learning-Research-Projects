{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc4130e1-15f2-4ee2-8b83-60a125ae9d5e",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "You work for an e-commerce company and want to predict whether a customer will make a purchase (Purchase: 1 = Yes, 0 = No). The dataset includes categorical features (like Region and Device_Type) and continuous features (like Browsing_Time and Total_Spent)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5302ee-34f5-4c91-b26a-118c491764eb",
   "metadata": {},
   "source": [
    "### Step 1: Generate the Dataset\n",
    "We will simulate a dataset with 1,000 rows, including categorical features and continuous features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e603485f-a55f-41ce-b758-1277b44b7be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "data = {\n",
    "    \"Age\": np.random.randint(18, 65, 1000),  # Continuous\n",
    "    \"Browsing_Time\": np.random.uniform(5, 120, 1000),  # Continuous\n",
    "    \"Clicks\": np.random.randint(1, 50, 1000),  # Continuous\n",
    "    \"Cart_Items\": np.random.randint(0, 10, 1000),  # Continuous\n",
    "    \"Total_Spent\": np.random.uniform(0, 500, 1000),  # Continuous\n",
    "    \"Discount_Code\": np.random.choice([0, 1], size=1000),  # Categorical\n",
    "    \"Device_Type\": np.random.choice([\"Mobile\", \"Desktop\", \"Tablet\"], size=1000),  # Categorical\n",
    "    \"Region\": np.random.choice([\"North\", \"South\", \"East\", \"West\"], size=1000),  # Categorical\n",
    "    \"Purchase\": np.random.choice([0, 1], size=1000),  # Target\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88937c21-2b22-4997-b151-3ef60106dbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Browsing_Time</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Cart_Items</th>\n",
       "      <th>Total_Spent</th>\n",
       "      <th>Discount_Code</th>\n",
       "      <th>Device_Type</th>\n",
       "      <th>Region</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>42.070692</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>315.123610</td>\n",
       "      <td>0</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>West</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>98.135561</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>124.191804</td>\n",
       "      <td>0</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>East</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>34.283675</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>352.730415</td>\n",
       "      <td>0</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>West</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>83.372813</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>213.800667</td>\n",
       "      <td>0</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>West</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>92.426204</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>221.272757</td>\n",
       "      <td>0</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>South</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Browsing_Time  Clicks  Cart_Items  Total_Spent  Discount_Code  \\\n",
       "0   56      42.070692       6           4   315.123610              0   \n",
       "1   46      98.135561      32           4   124.191804              0   \n",
       "2   32      34.283675      29           0   352.730415              0   \n",
       "3   60      83.372813      43           8   213.800667              0   \n",
       "4   25      92.426204       2           6   221.272757              0   \n",
       "\n",
       "  Device_Type Region  Purchase  \n",
       "0      Tablet   West         0  \n",
       "1      Tablet   East         0  \n",
       "2      Mobile   West         0  \n",
       "3      Tablet   West         0  \n",
       "4     Desktop  South         1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa993ee1-e9e7-4d3b-a3ef-bfa87248318c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 9)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d873213-834d-4a0a-9786-3acd1f8c1387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Age            1000 non-null   int32  \n",
      " 1   Browsing_Time  1000 non-null   float64\n",
      " 2   Clicks         1000 non-null   int32  \n",
      " 3   Cart_Items     1000 non-null   int32  \n",
      " 4   Total_Spent    1000 non-null   float64\n",
      " 5   Discount_Code  1000 non-null   int32  \n",
      " 6   Device_Type    1000 non-null   object \n",
      " 7   Region         1000 non-null   object \n",
      " 8   Purchase       1000 non-null   int32  \n",
      "dtypes: float64(2), int32(5), object(2)\n",
      "memory usage: 50.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af774d0e-dbcd-4dbc-b5b3-bdf86b2b3d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Device_Type\n",
       "Desktop    364\n",
       "Mobile     334\n",
       "Tablet     302\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Device_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "565d2095-a52b-4cfe-bc21-420ebb3a0569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Region\n",
       "South    260\n",
       "North    256\n",
       "East     249\n",
       "West     235\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e368dc9-94cd-4d7c-9b8f-7d631b58be6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Browsing_Time  Clicks  Cart_Items  Total_Spent  Discount_Code  \\\n",
      "0   56      42.070692       6           4   315.123610              0   \n",
      "1   46      98.135561      32           4   124.191804              0   \n",
      "2   32      34.283675      29           0   352.730415              0   \n",
      "3   60      83.372813      43           8   213.800667              0   \n",
      "4   25      92.426204       2           6   221.272757              0   \n",
      "\n",
      "   Device_Type  Region  Purchase  \n",
      "0            2       3         0  \n",
      "1            2       0         0  \n",
      "2            1       3         0  \n",
      "3            2       3         0  \n",
      "4            0       2         1  \n"
     ]
    }
   ],
   "source": [
    "# Encode categorical features for analysis\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df['Device_Type'] = LabelEncoder().fit_transform(df[\"Device_Type\"])\n",
    "df['Region'] = LabelEncoder().fit_transform(df[\"Region\"])\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cabaa4b1-64e5-462d-a92a-5feecc51fa82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Browsing_Time</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Cart_Items</th>\n",
       "      <th>Total_Spent</th>\n",
       "      <th>Discount_Code</th>\n",
       "      <th>Device_Type</th>\n",
       "      <th>Region</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>42.070692</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>315.123610</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>98.135561</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>124.191804</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>34.283675</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>352.730415</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>83.372813</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>213.800667</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>92.426204</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>221.272757</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Browsing_Time  Clicks  Cart_Items  Total_Spent  Discount_Code  \\\n",
       "0   56      42.070692       6           4   315.123610              0   \n",
       "1   46      98.135561      32           4   124.191804              0   \n",
       "2   32      34.283675      29           0   352.730415              0   \n",
       "3   60      83.372813      43           8   213.800667              0   \n",
       "4   25      92.426204       2           6   221.272757              0   \n",
       "\n",
       "   Device_Type  Region  Purchase  \n",
       "0            2       3         0  \n",
       "1            2       0         0  \n",
       "2            1       3         0  \n",
       "3            2       3         0  \n",
       "4            0       2         1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5166316-9ecb-4f22-8eda-fe27a34c5083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Device_Type\n",
       "0    364\n",
       "1    334\n",
       "2    302\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Device_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d80add7e-8850-4e1d-9134-e2a7bf233795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Region\n",
       "2    260\n",
       "1    256\n",
       "0    249\n",
       "3    235\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Region'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef914cc-2693-4474-b957-88881f07f9b9",
   "metadata": {},
   "source": [
    "### **Step 2: Apply Filter Methods**\n",
    "### 1. Variance Threshold (For Low-Variance Features):\n",
    "We will check if any features have low variance and remove them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fba3231a-311b-4e10-877d-b98341d2f52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Browsing_Time</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Cart_Items</th>\n",
       "      <th>Total_Spent</th>\n",
       "      <th>Discount_Code</th>\n",
       "      <th>Device_Type</th>\n",
       "      <th>Region</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>42.070692</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>315.123610</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>98.135561</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>124.191804</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>34.283675</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>352.730415</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>83.372813</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>213.800667</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>92.426204</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>221.272757</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Browsing_Time  Clicks  Cart_Items  Total_Spent  Discount_Code  \\\n",
       "0   56      42.070692       6           4   315.123610              0   \n",
       "1   46      98.135561      32           4   124.191804              0   \n",
       "2   32      34.283675      29           0   352.730415              0   \n",
       "3   60      83.372813      43           8   213.800667              0   \n",
       "4   25      92.426204       2           6   221.272757              0   \n",
       "\n",
       "   Device_Type  Region  Purchase  \n",
       "0            2       3         0  \n",
       "1            2       0         0  \n",
       "2            1       3         0  \n",
       "3            2       3         0  \n",
       "4            0       2         1  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "264fcd61-4299-498a-b425-b11247753cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VarianceThreshold(threshold=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;VarianceThreshold<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_selection.VarianceThreshold.html\">?<span>Documentation for VarianceThreshold</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>VarianceThreshold(threshold=0.01)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "VarianceThreshold(threshold=0.01)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Apply variance threshold\n",
    "selector = VarianceThreshold(threshold = 0.01)\n",
    "selector.fit(df.drop(columns=[\"Purchase\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d8a75ce2-d05f-490a-9392-cecfba54239b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-Variance Features: []\n"
     ]
    }
   ],
   "source": [
    "low_variance_features = df.drop(columns=[\"Purchase\"]).columns[~selector.get_support()]\n",
    "print(f\"Low-Variance Features: {list(low_variance_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389fa3eb-065d-4a73-b865-416448dcdf08",
   "metadata": {},
   "source": [
    "From the output of the code, we can infer the following:\n",
    "\n",
    "1. **No Low-Variance Features**:\n",
    "   - The `low_variance_features` list is empty (`[]`), which means that **none of the features in the dataset have variance below the specified threshold of `0.01`**.\n",
    "   - This implies that all features have sufficient variability in their values and may potentially carry useful information for the machine learning model.\n",
    "\n",
    "2. **Feature Variability**:\n",
    "   - All features in the dataset pass the variance threshold check, so no features will be dropped based on low variance.\n",
    "\n",
    "3. **Next Steps**:\n",
    "   - Since no features were removed due to low variance, we can proceed to apply other feature selection techniques (e.g., correlation, Chi-Square Test, ANOVA F-Test) to further evaluate feature importance and relevance to the target variable (`Purchase`).\n",
    "\n",
    "This result indicates that the dataset is well-prepared in terms of feature variance, and all features should initially be retained for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d917691-d7c9-4fcd-b931-01736683c7d5",
   "metadata": {},
   "source": [
    "These lines of code are applying a **Variance Threshold** filter method to remove features with low variance. Let’s break it down step by step:\n",
    "\n",
    "---\n",
    "\n",
    "### **Code Breakdown**\n",
    "\n",
    "#### **1. Import VarianceThreshold**\n",
    "```python\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "```\n",
    "- `VarianceThreshold` is a filter method from Scikit-learn's `feature_selection` module.\n",
    "- It identifies features with variance below a specified threshold and marks them for removal.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Initialize the VarianceThreshold**\n",
    "```python\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "```\n",
    "- `threshold=0.01`: This means any feature with variance less than `0.01` will be considered low variance and flagged for removal.\n",
    "- Variance measures how spread out the values in a feature are. For example:\n",
    "  - If all values in a column are the same (variance = 0), it provides no useful information for predictions.\n",
    "  - Features with very low variance contribute little to distinguishing between data points.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Apply VarianceThreshold to the Dataset**\n",
    "```python\n",
    "selector.fit(df.drop(columns=[\"Purchase\"]))\n",
    "```\n",
    "- `df.drop(columns=[\"Purchase\"])`: Excludes the target column (`Purchase`) from the analysis because we only want to evaluate the input features.\n",
    "- `.fit()`: Computes the variance of each feature in the dataset. The `selector` now knows which features have variance below the threshold (`0.01`).\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Identify Low-Variance Features**\n",
    "```python\n",
    "low_variance_features = df.drop(columns=[\"Purchase\"]).columns[~selector.get_support()]\n",
    "```\n",
    "- `selector.get_support()`: Returns a Boolean array indicating which features are **kept** (True) based on the threshold.\n",
    "  - Example:\n",
    "    - If there are 5 features and 3 pass the threshold, `get_support()` returns `[True, True, False, True, False]`.\n",
    "- `~selector.get_support()`: The `~` operator inverts the Boolean array, marking the features that **do not pass** the threshold (low variance features).\n",
    "  - Example:\n",
    "    - Inverted array: `[False, False, True, False, True]`.\n",
    "- `df.columns[~selector.get_support()]`: Selects the column names corresponding to the `False` values (low-variance features).\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Print Low-Variance Features**\n",
    "```python\n",
    "print(f\"Low-Variance Features: {list(low_variance_features)}\")\n",
    "```\n",
    "- `list(low_variance_features)`: Converts the column names of low-variance features into a list.\n",
    "- Prints the names of the features with variance below `0.01`.\n",
    "\n",
    "---\n",
    "\n",
    "### **What Does This Do?**\n",
    "This code:\n",
    "1. Computes the variance of each feature in the dataset.\n",
    "2. Flags features with variance below `0.01`.\n",
    "3. Identifies and outputs the names of these low-variance features, which you can choose to drop from the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Is This Important?**\n",
    "Low-variance features often:\n",
    "- Provide little to no meaningful information.\n",
    "- Increase the complexity of the model without improving its performance.\n",
    "- Should be removed to simplify the dataset and improve efficiency.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example**\n",
    "Imagine a dataset:\n",
    "\n",
    "| Feature1 | Feature2 | Feature3 | Purchase |\n",
    "|----------|----------|----------|----------|\n",
    "| 0.01     | Mobile   | 1        | 1        |\n",
    "| 0.01     | Desktop  | 1        | 0        |\n",
    "| 0.01     | Tablet   | 1        | 1        |\n",
    "\n",
    "- `Feature1`: All values are nearly identical, so its variance is very low.\n",
    "- `Feature3`: All values are the same (`1`), so its variance is `0`.\n",
    "\n",
    "After running the code, the output might be:\n",
    "```plaintext\n",
    "Low-Variance Features: ['Feature1', 'Feature3']\n",
    "```\n",
    "\n",
    "These features can be dropped as they provide no useful information for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe11f44c-3217-469f-a904-62127aea4803",
   "metadata": {},
   "source": [
    "### 2. Correlation Coefficient (For Continuous Features)\n",
    "\n",
    "We calculate the correlation between continuous features and the target (Purchase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b822f685-f3db-4a71-a0a8-5a874d5154cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Browsing_Time</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Cart_Items</th>\n",
       "      <th>Total_Spent</th>\n",
       "      <th>Discount_Code</th>\n",
       "      <th>Device_Type</th>\n",
       "      <th>Region</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.043343</td>\n",
       "      <td>-0.060234</td>\n",
       "      <td>0.011149</td>\n",
       "      <td>0.060819</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.023240</td>\n",
       "      <td>-0.028701</td>\n",
       "      <td>-0.003390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Browsing_Time</th>\n",
       "      <td>-0.043343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.041035</td>\n",
       "      <td>0.025660</td>\n",
       "      <td>0.051577</td>\n",
       "      <td>-0.021170</td>\n",
       "      <td>-0.048452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clicks</th>\n",
       "      <td>-0.060234</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024454</td>\n",
       "      <td>0.072630</td>\n",
       "      <td>-0.021259</td>\n",
       "      <td>0.029652</td>\n",
       "      <td>0.048357</td>\n",
       "      <td>0.002869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cart_Items</th>\n",
       "      <td>0.011149</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.024454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008352</td>\n",
       "      <td>-0.028800</td>\n",
       "      <td>-0.005198</td>\n",
       "      <td>-0.002173</td>\n",
       "      <td>0.043563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Spent</th>\n",
       "      <td>0.060819</td>\n",
       "      <td>0.041035</td>\n",
       "      <td>0.072630</td>\n",
       "      <td>-0.008352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031412</td>\n",
       "      <td>-0.008481</td>\n",
       "      <td>-0.013520</td>\n",
       "      <td>-0.017470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discount_Code</th>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.025660</td>\n",
       "      <td>-0.021259</td>\n",
       "      <td>-0.028800</td>\n",
       "      <td>0.031412</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005969</td>\n",
       "      <td>-0.013494</td>\n",
       "      <td>-0.041132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Device_Type</th>\n",
       "      <td>0.023240</td>\n",
       "      <td>0.051577</td>\n",
       "      <td>0.029652</td>\n",
       "      <td>-0.005198</td>\n",
       "      <td>-0.008481</td>\n",
       "      <td>-0.005969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015790</td>\n",
       "      <td>-0.032892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region</th>\n",
       "      <td>-0.028701</td>\n",
       "      <td>-0.021170</td>\n",
       "      <td>0.048357</td>\n",
       "      <td>-0.002173</td>\n",
       "      <td>-0.013520</td>\n",
       "      <td>-0.013494</td>\n",
       "      <td>-0.015790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purchase</th>\n",
       "      <td>-0.003390</td>\n",
       "      <td>-0.048452</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.043563</td>\n",
       "      <td>-0.017470</td>\n",
       "      <td>-0.041132</td>\n",
       "      <td>-0.032892</td>\n",
       "      <td>0.013941</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Age  Browsing_Time    Clicks  Cart_Items  Total_Spent  \\\n",
       "Age            1.000000      -0.043343 -0.060234    0.011149     0.060819   \n",
       "Browsing_Time -0.043343       1.000000  0.015501    0.025316     0.041035   \n",
       "Clicks        -0.060234       0.015501  1.000000    0.024454     0.072630   \n",
       "Cart_Items     0.011149       0.025316  0.024454    1.000000    -0.008352   \n",
       "Total_Spent    0.060819       0.041035  0.072630   -0.008352     1.000000   \n",
       "Discount_Code  0.007966       0.025660 -0.021259   -0.028800     0.031412   \n",
       "Device_Type    0.023240       0.051577  0.029652   -0.005198    -0.008481   \n",
       "Region        -0.028701      -0.021170  0.048357   -0.002173    -0.013520   \n",
       "Purchase      -0.003390      -0.048452  0.002869    0.043563    -0.017470   \n",
       "\n",
       "               Discount_Code  Device_Type    Region  Purchase  \n",
       "Age                 0.007966     0.023240 -0.028701 -0.003390  \n",
       "Browsing_Time       0.025660     0.051577 -0.021170 -0.048452  \n",
       "Clicks             -0.021259     0.029652  0.048357  0.002869  \n",
       "Cart_Items         -0.028800    -0.005198 -0.002173  0.043563  \n",
       "Total_Spent         0.031412    -0.008481 -0.013520 -0.017470  \n",
       "Discount_Code       1.000000    -0.005969 -0.013494 -0.041132  \n",
       "Device_Type        -0.005969     1.000000 -0.015790 -0.032892  \n",
       "Region             -0.013494    -0.015790  1.000000  0.013941  \n",
       "Purchase           -0.041132    -0.032892  0.013941  1.000000  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "269b574f-08b2-463e-81b4-a68484478905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation with Target:\n",
      " Purchase         1.000000\n",
      "Cart_Items       0.043563\n",
      "Region           0.013941\n",
      "Clicks           0.002869\n",
      "Age             -0.003390\n",
      "Total_Spent     -0.017470\n",
      "Device_Type     -0.032892\n",
      "Discount_Code   -0.041132\n",
      "Browsing_Time   -0.048452\n",
      "Name: Purchase, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Extract correlation with the target\n",
    "correlation_with_target = correlation_matrix[\"Purchase\"].sort_values(ascending=False)\n",
    "print(\"Correlation with Target:\\n\", correlation_with_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b53d39-8ecb-46ab-ba53-d11295ebf595",
   "metadata": {},
   "source": [
    "From the output of the correlation analysis, we can infer the following:\n",
    "\n",
    "### **Key Observations:**\n",
    "1. **Purchase (Target Variable)**:\n",
    "   - The correlation of `Purchase` with itself is always 1 (as expected, because it’s perfectly correlated with itself).\n",
    "\n",
    "2. **Cart_Items**:\n",
    "   - Has the **highest positive correlation (0.043563)** with `Purchase` among the features.\n",
    "   - This suggests that customers adding more items to their cart might have a slight tendency to make a purchase. However, the correlation is very weak (close to 0), so it’s not a strong predictor.\n",
    "\n",
    "3. **Region** and **Clicks**:\n",
    "   - Have very weak positive correlations with `Purchase` (0.013941 and 0.002869, respectively).\n",
    "   - These features might not have much influence on predicting whether a customer makes a purchase.\n",
    "\n",
    "4. **Age, Total_Spent, Device_Type, Discount_Code, Browsing_Time**:\n",
    "   - All have **negative correlations** with `Purchase`, meaning an increase in these features might slightly decrease the likelihood of a purchase.\n",
    "   - Among these, `Browsing_Time` (-0.048452) has the strongest negative correlation with `Purchase`, suggesting that spending more time browsing might reduce the likelihood of making a purchase (perhaps due to indecision or browsing without intent).\n",
    "\n",
    "---\n",
    "\n",
    "### **Insights from Correlation Values:**\n",
    "- **Weak Correlations Overall**:\n",
    "   - None of the features have a strong correlation (close to 1 or -1) with the target variable `Purchase`. This means that individually, these features may not be strong predictors of whether a customer makes a purchase.\n",
    "   \n",
    "- **Potentially Useful Features**:\n",
    "   - While the correlations are weak, `Cart_Items` has the highest positive correlation, so it might still add some predictive power when used in combination with other features.\n",
    "\n",
    "---\n",
    "\n",
    "### **Next Steps:**\n",
    "1. **Further Feature Selection**:\n",
    "   - Combine this correlation analysis with other feature selection methods (e.g., Chi-Square Test, ANOVA F-Test) to assess feature relevance in different ways.\n",
    "   \n",
    "2. **Modeling and Interaction Effects**:\n",
    "   - Sometimes features with weak individual correlations can become important when combined with others (interaction effects). Consider including features like `Cart_Items` and testing their importance in the model.\n",
    "\n",
    "3. **Feature Engineering**:\n",
    "   - Create new features (e.g., `Cart_Items * Discount_Code`) to capture potential interactions not visible in the correlation matrix.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**:\n",
    "- The correlation values suggest weak relationships between the individual features and `Purchase`.\n",
    "- While `Cart_Items` shows the most promise, the weak correlations highlight the need for further analysis or model-based feature selection methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f43826b-94e4-467c-b39c-70c18af45701",
   "metadata": {},
   "source": [
    "### 3. Chi-Square Test (For Categorical Features)\n",
    "\n",
    "We use the Chi-Square test to measure the dependency between categorical features (Discount_Code, Device_Type, Region) and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9e397dbf-bd2a-4ec0-ae64-135e1648189f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Feature  Chi-Square   P-Value\n",
      "0  Discount_Code    0.884823  0.346884\n",
      "1    Device_Type    0.763736  0.382162\n",
      "2         Region    0.159783  0.689356\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Select categorical features:\n",
    "categorical_features = df[[\"Discount_Code\", \"Device_Type\", \"Region\"]]\n",
    "chi_scores, p_values = chi2(categorical_features, df[\"Purchase\"])\n",
    "\n",
    "chi_square_results = pd.DataFrame({\"Feature\":categorical_features.columns, \"Chi-Square\": chi_scores, \"P-Value\": p_values})\n",
    "print(chi_square_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0793d0c-6d39-43b4-965c-cea5c3994fb5",
   "metadata": {},
   "source": [
    "From the results of the Chi-Square test:\n",
    "\n",
    "### **Understanding the Results**\n",
    "1. **Chi-Square Test**:\n",
    "   - The Chi-Square test evaluates the dependency between categorical features (`Discount_Code`, `Device_Type`, and `Region`) and the target variable (`Purchase`).\n",
    "   - Higher Chi-Square values indicate stronger dependency (more influence on the target).\n",
    "   - P-values tell us the statistical significance of this dependency. A low p-value (< 0.05) suggests that the feature is significantly related to the target.\n",
    "\n",
    "2. **Feature Analysis**:\n",
    "   - **Discount_Code**:\n",
    "     - Chi-Square = 0.884823\n",
    "     - P-value = 0.346884\n",
    "     - The high p-value suggests that `Discount_Code` is not significantly associated with `Purchase`.\n",
    "   - **Device_Type**:\n",
    "     - Chi-Square = 0.763736\n",
    "     - P-value = 0.382162\n",
    "     - Again, the high p-value indicates no significant association between `Device_Type` and `Purchase`.\n",
    "   - **Region**:\n",
    "     - Chi-Square = 0.159783\n",
    "     - P-value = 0.689356\n",
    "     - `Region` has an even higher p-value, confirming no strong dependency with `Purchase`.\n",
    "\n",
    "---\n",
    "\n",
    "### **What Can Be Inferred?**\n",
    "1. **No Significant Dependency**:\n",
    "   - None of the tested categorical features (`Discount_Code`, `Device_Type`, `Region`) show a significant relationship with the target variable `Purchase` based on the high p-values (all above 0.05).\n",
    "\n",
    "2. **Feature Exclusion**:\n",
    "   - These categorical features might not be valuable for predicting `Purchase` and can potentially be excluded from the model. However, it's worth checking interaction effects or combining them with other features before outright removal.\n",
    "\n",
    "3. **Next Steps**:\n",
    "   - Further analysis with other feature selection methods (e.g., wrapper or embedded methods) could provide additional insights.\n",
    "   - Consider creating interaction terms or conducting feature engineering to identify hidden patterns not captured by the Chi-Square test.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**:\n",
    "Based on the Chi-Square results, none of the categorical features appear to have a strong or statistically significant relationship with `Purchase`. This indicates they might not contribute much to the predictive power of the model but should be further analyzed before exclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b237a31-1f01-4aa1-af39-9406f355efdb",
   "metadata": {},
   "source": [
    "You're absolutely correct that **higher Chi-Square values generally indicate a stronger dependency between the feature and the target variable**. Let’s clarify the results and address this apparent contradiction.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Points to Understand**\n",
    "\n",
    "1. **Chi-Square Value**:\n",
    "   - A high Chi-Square value (e.g., for `Discount_Code` and `Device_Type`) suggests that there **may be a relationship** between the feature and the target (`Purchase`).\n",
    "   - However, **Chi-Square alone does not determine significance**; it must be interpreted in conjunction with the **P-value**.\n",
    "\n",
    "2. **P-Value**:\n",
    "   - The **P-value** indicates whether the observed Chi-Square value is statistically significant (i.e., unlikely to occur by chance).\n",
    "   - A low P-value (< 0.05) means the feature's association with the target is statistically significant.\n",
    "   - A high P-value (> 0.05) suggests that the Chi-Square value is not significant, even if it's high numerically.\n",
    "\n",
    "---\n",
    "\n",
    "### **Interpreting the Results**\n",
    "\n",
    "#### **1. Discount_Code**\n",
    "- **Chi-Square = 0.884823**: A relatively high value.\n",
    "- **P-value = 0.346884**: Indicates that the relationship between `Discount_Code` and `Purchase` is **not statistically significant**. In other words, while `Discount_Code` may show some association with `Purchase`, this relationship might be due to random chance.\n",
    "\n",
    "#### **2. Device_Type**\n",
    "- **Chi-Square = 0.763736**: Also relatively high.\n",
    "- **P-value = 0.382162**: Again, this suggests the association between `Device_Type` and `Purchase` is **not statistically significant**.\n",
    "\n",
    "#### **3. Region**\n",
    "- **Chi-Square = 0.159783**: A low value.\n",
    "- **P-value = 0.689356**: Indicates no significant relationship between `Region` and `Purchase`.\n",
    "\n",
    "---\n",
    "\n",
    "### **How to Think About This?**\n",
    "- A **high Chi-Square value** without a **low P-value** means the observed association may not be meaningful.\n",
    "- **P-values are crucial for deciding statistical significance**. Without a low P-value, you cannot confidently say the feature has a real dependency on the target variable.\n",
    "\n",
    "---\n",
    "\n",
    "### **What Should You Do Next?**\n",
    "1. **Keep Discount_Code and Device_Type for Further Testing**:\n",
    "   - Since these features have relatively higher Chi-Square values, you may keep them for further analysis using other techniques (e.g., feature importance in tree-based models).\n",
    "   - Even though the P-values are high, these features could still contribute to model performance in combination with other features.\n",
    "\n",
    "2. **Consider Removing Region**:\n",
    "   - `Region` has both a low Chi-Square value and a high P-value, suggesting it’s likely irrelevant for predicting `Purchase`.\n",
    "\n",
    "3. **Check Feature Interactions**:\n",
    "   - Sometimes, a feature might not show a significant relationship individually but could be important in interaction with other features. For example, `Discount_Code` might interact with `Device_Type` (e.g., discounts might work better on mobile devices).\n",
    "\n",
    "4. **Model Validation**:\n",
    "   - Ultimately, use your model’s performance metrics (e.g., accuracy, AUC-ROC) to validate the usefulness of these features.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "- A high Chi-Square value indicates potential influence, but without a low P-value, it’s not statistically significant.\n",
    "- Keep `Discount_Code` and `Device_Type` for further investigation, and consider dropping `Region` based on this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904be4a6-27fb-4788-b399-f278159b15be",
   "metadata": {},
   "source": [
    "### 4. ANOVA F-Test (For Continuous Features)\n",
    "\n",
    "The ANOVA F-test evaluates the relationship between continuous features and the categorical target (Purchase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6ba8aff4-ff91-493e-90ee-8d33a2513016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Feature   F-Score   P-Value\n",
      "0            Age  0.011466  0.914746\n",
      "1  Browsing_Time  2.348455  0.125724\n",
      "2         Clicks  0.008213  0.927807\n",
      "3     Cart_Items  1.897531  0.168664\n",
      "4    Total_Spent  0.304670  0.581093\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Select continuous features\n",
    "continuous_features = df[[\"Age\", \"Browsing_Time\", \"Clicks\", \"Cart_Items\", \"Total_Spent\"]]\n",
    "\n",
    "# Apply ANOVA F-Test\n",
    "f_scores, p_values = f_classif(continuous_features, df['Purchase'])\n",
    "\n",
    "anova_results = pd.DataFrame({\"Feature\": continuous_features.columns, \"F-Score\": f_scores, \"P-Value\":p_values})\n",
    "print(anova_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe8208c-bf81-4016-9818-07a8dfa5e0dc",
   "metadata": {},
   "source": [
    "From the results of the **ANOVA F-Test**, we can draw the following inferences:\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Observations**\n",
    "\n",
    "1. **F-Score**:\n",
    "   - The F-Score measures the ratio of variance explained by the feature compared to the variance within the data. A higher F-Score indicates that the feature is more relevant in distinguishing between the classes of the target (`Purchase`).\n",
    "\n",
    "2. **P-Value**:\n",
    "   - The P-value indicates whether the F-Score is statistically significant. A low P-value (< 0.05) suggests the feature is significantly related to the target variable.\n",
    "   - If the P-value is high (> 0.05), it implies the feature does not significantly contribute to predicting the target.\n",
    "\n",
    "---\n",
    "\n",
    "### **Feature Analysis**\n",
    "\n",
    "#### **1. Age**\n",
    "   - **F-Score = 0.011466**\n",
    "   - **P-Value = 0.914746**\n",
    "   - The very low F-Score and high P-value suggest that `Age` has no significant relationship with `Purchase`.\n",
    "\n",
    "#### **2. Browsing_Time**\n",
    "   - **F-Score = 2.348455**\n",
    "   - **P-Value = 0.125724**\n",
    "   - The F-Score is relatively higher, but the P-value is above 0.05, indicating that `Browsing_Time` does not significantly differentiate between customers who make a purchase and those who don’t.\n",
    "\n",
    "#### **3. Clicks**\n",
    "   - **F-Score = 0.008213**\n",
    "   - **P-Value = 0.927807**\n",
    "   - The low F-Score and high P-value suggest that `Clicks` is not a significant predictor of `Purchase`.\n",
    "\n",
    "#### **4. Cart_Items**\n",
    "   - **F-Score = 1.897531**\n",
    "   - **P-Value = 0.168664**\n",
    "   - While `Cart_Items` has a higher F-Score compared to some other features, the P-value is still above 0.05, meaning it is not statistically significant.\n",
    "\n",
    "#### **5. Total_Spent**\n",
    "   - **F-Score = 0.304670**\n",
    "   - **P-Value = 0.581093**\n",
    "   - The low F-Score and high P-value suggest that `Total_Spent` is not a significant predictor of `Purchase`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Overall Inferences**\n",
    "1. **No Feature is Statistically Significant**:\n",
    "   - None of the continuous features (`Age`, `Browsing_Time`, `Clicks`, `Cart_Items`, `Total_Spent`) have P-values below 0.05, indicating that they do not significantly contribute to predicting `Purchase`.\n",
    "\n",
    "2. **Relative Importance**:\n",
    "   - While not statistically significant, `Browsing_Time` and `Cart_Items` have relatively higher F-Scores, suggesting they might still carry some predictive power when combined with other features or through feature engineering.\n",
    "\n",
    "3. **Irrelevant Features**:\n",
    "   - `Age`, `Clicks`, and `Total_Spent` have very low F-Scores and high P-values, suggesting they contribute very little and can potentially be dropped.\n",
    "\n",
    "---\n",
    "\n",
    "### **Next Steps**\n",
    "1. **Feature Engineering**:\n",
    "   - Create interaction terms (e.g., `Cart_Items * Discount_Code`) or transformations (e.g., log of `Browsing_Time`) to uncover hidden patterns.\n",
    "2. **Model-Based Feature Selection**:\n",
    "   - Use tree-based models (e.g., Random Forest) to evaluate feature importance in a more flexible way, as they can capture non-linear relationships and interactions.\n",
    "3. **Validation Through Modeling**:\n",
    "   - Validate the results by training a machine learning model and analyzing its performance with and without these features.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "None of the continuous features are statistically significant predictors of `Purchase` individually. However, `Browsing_Time` and `Cart_Items` might still hold some value and should be retained for further investigation, while `Age`, `Clicks`, and `Total_Spent` are likely candidates for removal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1c86a5-38b9-4ffb-a83b-43d64c289d30",
   "metadata": {},
   "source": [
    "### Summary\n",
    "- Variance Threshold: Identified and removed low-variance features.\n",
    "- Correlation Analysis: Kept continuous features with strong correlation to the target.\n",
    "- Chi-Square Test: Selected categorical features highly dependent on the target.\n",
    "- ANOVA F-Test: Chose continuous features significantly related to the target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0338c6-d3e6-4522-9386-f80381d2f7c7",
   "metadata": {},
   "source": [
    "## Using Wrapper Method for feature selection\n",
    "\n",
    "Wrapper methods use a machine learning model to evaluate subsets of features. They are computationally more expensive than filter methods but often provide better results because they are model-specific.\n",
    "\n",
    "In other words, Wrapper methods involve selecting features based on their impact on a machine learning model's performance. Unlike filter methods, wrapper methods evaluate subsets of features by training models and measuring performance, making them computationally intensive but often more accurate.\n",
    "\n",
    "Here’s how we can use wrapper methods step by step:\n",
    "\n",
    "### 1. Forward Selection:\n",
    "Forward selection starts with no features and adds features one by one, selecting the feature that improves the model's performance the most at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d19e5f42-c438-4897-a69d-19d712b24d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Browsing_Time</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Cart_Items</th>\n",
       "      <th>Total_Spent</th>\n",
       "      <th>Discount_Code</th>\n",
       "      <th>Device_Type</th>\n",
       "      <th>Region</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>42.070692</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>315.123610</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>98.135561</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>124.191804</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>34.283675</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>352.730415</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>83.372813</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>213.800667</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>92.426204</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>221.272757</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Browsing_Time  Clicks  Cart_Items  Total_Spent  Discount_Code  \\\n",
       "0   56      42.070692       6           4   315.123610              0   \n",
       "1   46      98.135561      32           4   124.191804              0   \n",
       "2   32      34.283675      29           0   352.730415              0   \n",
       "3   60      83.372813      43           8   213.800667              0   \n",
       "4   25      92.426204       2           6   221.272757              0   \n",
       "\n",
       "   Device_Type  Region  Purchase  \n",
       "0            2       3         0  \n",
       "1            2       0         0  \n",
       "2            1       3         0  \n",
       "3            2       3         0  \n",
       "4            0       2         1  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fee3b1a5-67d7-45c5-80a5-d704db1131fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Selected Features: ['Cart_Items', 'Discount_Code', 'Device_Type', 'Region']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df.drop(columns=[\"Purchase\"])\n",
    "y = df['Purchase']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "model = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Apply forward selection\n",
    "sfs_forward = SequentialFeatureSelector(model, n_features_to_select = \"auto\", direction=\"forward\", cv=5)\n",
    "sfs_forward.fit(X_train, y_train)\n",
    "\n",
    "# selected features\n",
    "forward_selected_features = X_train.columns[sfs_forward.get_support()]\n",
    "print(\"Forward Selected Features:\", list(forward_selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8f687c-a692-41ab-9960-1b4ee5c4ee2f",
   "metadata": {},
   "source": [
    "### **Explanation of Code and Results**\n",
    "\n",
    "#### **1. Import Required Libraries**\n",
    "```python\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "```\n",
    "- **SequentialFeatureSelector**: A wrapper method for feature selection that adds or removes features sequentially to find the best subset.\n",
    "- **LogisticRegression**: A machine learning algorithm used here to evaluate the importance of features.\n",
    "- **train_test_split**: Splits the dataset into training and testing sets.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Split the Dataset into Features and Target**\n",
    "```python\n",
    "X = df.drop(columns=[\"Purchase\"])\n",
    "y = df[\"Purchase\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "```\n",
    "- **`X`**: Contains all features (independent variables) by dropping the target column (`Purchase`).\n",
    "- **`y`**: Contains the target column (`Purchase`).\n",
    "- **`train_test_split`**:\n",
    "  - Splits the dataset into:\n",
    "    - Training set: 70% of the data (used for feature selection and model training).\n",
    "    - Testing set: 30% of the data (reserved for validation).\n",
    "  - **`random_state=42`** ensures reproducibility (same split every time).\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Create a Logistic Regression Model**\n",
    "```python\n",
    "model = LogisticRegression(max_iter=500)\n",
    "```\n",
    "- **LogisticRegression**:\n",
    "  - A classification model used here to evaluate the performance of different feature subsets.\n",
    "  - **`max_iter=500`** increases the number of iterations for convergence (default is 100).\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Apply Forward Selection**\n",
    "```python\n",
    "sfs_forward = SequentialFeatureSelector(model, n_features_to_select=\"auto\", direction=\"forward\", cv=5)\n",
    "sfs_forward.fit(X_train, y_train)\n",
    "```\n",
    "- **`SequentialFeatureSelector`**:\n",
    "  - A wrapper method for feature selection that uses cross-validation to evaluate feature subsets.\n",
    "  - **`direction=\"forward\"`**:\n",
    "    - Starts with no features and adds one feature at a time.\n",
    "    - At each step, it selects the feature that improves model performance the most (based on the `model` provided).\n",
    "  - **`n_features_to_select=\"auto\"`**:\n",
    "    - Automatically selects the optimal number of features by cross-validation (using 5 folds here, `cv=5`).\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Extract Selected Features**\n",
    "```python\n",
    "forward_selected_features = X_train.columns[sfs_forward.get_support()]\n",
    "print(\"Forward Selected Features:\", list(forward_selected_features))\n",
    "```\n",
    "- **`sfs_forward.get_support()`**:\n",
    "  - Returns a Boolean array indicating which features were selected (`True` for selected features).\n",
    "- **`X_train.columns[sfs_forward.get_support()]`**:\n",
    "  - Extracts the names of the features corresponding to `True` values in the Boolean array.\n",
    "\n",
    "---\n",
    "\n",
    "### **Results**\n",
    "```plaintext\n",
    "Forward Selected Features: ['Cart_Items', 'Discount_Code', 'Device_Type', 'Region']\n",
    "```\n",
    "\n",
    "#### **Interpretation of Results**\n",
    "1. **Selected Features**:\n",
    "   - The forward selection process identified the following features as the most important for predicting `Purchase`:\n",
    "     - **Cart_Items**: Number of items added to the cart.\n",
    "     - **Discount_Code**: Whether a discount code was used.\n",
    "     - **Device_Type**: The type of device (e.g., mobile, desktop).\n",
    "     - **Region**: The customer's region (e.g., North, South).\n",
    "\n",
    "2. **Importance of These Features**:\n",
    "   - These features were chosen because they contribute the most to the model's performance when added to the subset.\n",
    "   - For example:\n",
    "     - Customers who add more items to their cart (Cart_Items) might be more likely to purchase.\n",
    "     - Discount codes and device types could influence purchasing decisions.\n",
    "\n",
    "3. **Optimal Subset**:\n",
    "   - By selecting these features, the model can be trained more efficiently (fewer features mean less complexity) while retaining high predictive power.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Forward Selection?**\n",
    "- Forward selection is useful because it:\n",
    "  - Iteratively builds the best feature subset by adding features one at a time.\n",
    "  - Avoids evaluating all possible subsets (which would be computationally expensive).\n",
    "\n",
    "This method ensures that only the most relevant features are included in the model, helping reduce overfitting and improving interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e621c961-2c1d-4d7d-8f56-866507cd9195",
   "metadata": {},
   "source": [
    "### 2. Backward Elimination\n",
    "\n",
    "Backward elimination starts with all features and removes the least important feature one by one, based on its impact on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a238def8-ab42-4061-9ff9-933b9032bf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward Selected Features: ['Cart_Items', 'Discount_Code', 'Device_Type', 'Region']\n"
     ]
    }
   ],
   "source": [
    "# Apply Backward Elimination\n",
    "sfs_backward = SequentialFeatureSelector(model, n_features_to_select=\"auto\", direction=\"backward\", cv=5)\n",
    "sfs_backward.fit(X_train, y_train)\n",
    "\n",
    "# Selected features\n",
    "backward_selected_features = X_train.columns[sfs_backward.get_support()]\n",
    "print(\"Backward Selected Features:\", list(backward_selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafd5b7c-abc1-45a8-88d5-ae1efe7944ed",
   "metadata": {},
   "source": [
    "### **Explanation of the Code and Inference**\n",
    "\n",
    "#### **What Does the Code Do?**\n",
    "\n",
    "1. **Backward Elimination**:\n",
    "   - Starts with all features and removes the least important one-by-one, based on the model's performance.\n",
    "   - The process continues until it finds the best subset of features.\n",
    "\n",
    "2. **Steps in Code**:\n",
    "   - **SequentialFeatureSelector**:\n",
    "     - Uses a logistic regression model to evaluate feature importance.\n",
    "     - **`direction=\"backward\"`** specifies that it starts with all features and eliminates them sequentially.\n",
    "     - **`n_features_to_select=\"auto\"`** automatically determines the optimal number of features using 5-fold cross-validation (`cv=5`).\n",
    "   - **`sfs_backward.get_support()`**:\n",
    "     - Returns a Boolean mask of the features retained by the backward elimination process.\n",
    "   - **Selected Features**:\n",
    "     - Extracted by filtering `X_train.columns` with the Boolean mask.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Result Output**\n",
    "```plaintext\n",
    "Backward Selected Features: ['Cart_Items', 'Discount_Code', 'Device_Type', 'Region']\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Inferences**\n",
    "\n",
    "1. **Selected Features**:\n",
    "   - The backward elimination process retained the following features:\n",
    "     - **Cart_Items**: Likely significant because the number of items in the cart may indicate the likelihood of making a purchase.\n",
    "     - **Discount_Code**: Indicates whether the use of discounts influences purchases.\n",
    "     - **Device_Type**: Shows if device preferences (e.g., mobile, desktop) affect purchasing behavior.\n",
    "     - **Region**: Highlights if customer location plays a role in purchase behavior.\n",
    "\n",
    "2. **Consistency**:\n",
    "   - The selected features from backward elimination are the same as those selected by forward selection. This suggests strong agreement between the two methods, which further validates the importance of these features.\n",
    "\n",
    "3. **Importance of Features**:\n",
    "   - These features likely contribute the most to the predictive power of the logistic regression model.\n",
    "\n",
    "4. **Optimal Subset**:\n",
    "   - The selected features represent the most relevant subset for training the model, improving efficiency while maintaining performance.\n",
    "\n",
    "---\n",
    "\n",
    "### **Next Steps**\n",
    "1. **Model Training**:\n",
    "   - Train a logistic regression model or other machine learning algorithms using only the selected features to evaluate the impact on performance.\n",
    "2. **Validation**:\n",
    "   - Compare the performance (e.g., accuracy, F1-score, AUC-ROC) of models trained on the selected features versus all features.\n",
    "3. **Comparison with Other Methods**:\n",
    "   - Validate these results against Recursive Feature Elimination (RFE) to ensure consistency across wrapper methods.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "Backward elimination identified the same feature set as forward selection (`Cart_Items`, `Discount_Code`, `Device_Type`, and `Region`), suggesting that these are the most important features in predicting the target (`Purchase`). These features can be used for model building and optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9306410f-5e98-4975-84a2-293657ee6d7b",
   "metadata": {},
   "source": [
    "### 3. Recursive Feature Elimination (RFE)\n",
    "RFE works by recursively removing the least important feature, based on the model’s feature importance scores, until the desired number of features is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "30cb4758-9521-425b-900a-2f7c47d75e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE Selected Features: ['Age', 'Cart_Items', 'Discount_Code', 'Device_Type', 'Region']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Apply Recursive Feature Elimination\n",
    "rfe_selector = RFE(estimator=model, n_features_to_select=5)\n",
    "rfe_selector.fit(X_train, y_train)\n",
    "\n",
    "# selected features:\n",
    "rfe_selected_features = X_train.columns[rfe_selector.support_]\n",
    "print(\"RFE Selected Features:\", list(rfe_selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "389d3eb8-2c70-4afa-a5ab-ab74135763e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Rankings:\n",
      "         Feature  Rank\n",
      "0            Age     1\n",
      "3     Cart_Items     1\n",
      "5  Discount_Code     1\n",
      "6    Device_Type     1\n",
      "7         Region     1\n",
      "1  Browsing_Time     2\n",
      "2         Clicks     3\n",
      "4    Total_Spent     4\n"
     ]
    }
   ],
   "source": [
    "# Import RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Apply Recursive Feature Elimination\n",
    "rfe_selector = RFE(estimator=model, n_features_to_select=5)\n",
    "rfe_selector.fit(X_train, y_train)\n",
    "\n",
    "# Extract rankings\n",
    "feature_ranks = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Rank\": rfe_selector.ranking_\n",
    "}).sort_values(by=\"Rank\")\n",
    "\n",
    "# Display ranked features\n",
    "print(\"Feature Rankings:\")\n",
    "print(feature_ranks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36914f30-aa83-4385-b2f2-0782fdc1ef5f",
   "metadata": {},
   "source": [
    "### **Explanation of Code and Output**\n",
    "\n",
    "#### **Code Breakdown**\n",
    "\n",
    "##### **1. Import the Recursive Feature Elimination (RFE) Module**\n",
    "```python\n",
    "from sklearn.feature_selection import RFE\n",
    "```\n",
    "- **RFE**:\n",
    "  - A wrapper method for feature selection.\n",
    "  - Recursively removes the least important features based on the model's feature importance until the desired number of features is reached.\n",
    "\n",
    "---\n",
    "\n",
    "##### **2. Apply Recursive Feature Elimination**\n",
    "```python\n",
    "rfe_selector = RFE(estimator=model, n_features_to_select=5)\n",
    "rfe_selector.fit(X_train, y_train)\n",
    "```\n",
    "- **`estimator=model`**:\n",
    "  - Specifies the machine learning model used to evaluate feature importance. Here, it’s a logistic regression model (`model`).\n",
    "- **`n_features_to_select=5`**:\n",
    "  - The number of features to retain. RFE will keep the top 5 most important features based on the logistic regression model.\n",
    "- **`fit(X_train, y_train)`**:\n",
    "  - Fits the RFE algorithm to the training dataset (`X_train`, `y_train`), iteratively eliminating features until 5 remain.\n",
    "\n",
    "---\n",
    "\n",
    "##### **3. Extract Selected Features**\n",
    "```python\n",
    "rfe_selected_features = X_train.columns[rfe_selector.support_]\n",
    "print(\"RFE Selected Features:\", list(rfe_selected_features))\n",
    "```\n",
    "- **`rfe_selector.support_`**:\n",
    "  - A Boolean mask where `True` indicates the selected features, and `False` indicates the removed features.\n",
    "- **`X_train.columns[rfe_selector.support_]`**:\n",
    "  - Filters the column names in `X_train` to include only the selected features.\n",
    "- **Output**:\n",
    "  - Displays the names of the top 5 selected features based on RFE.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Output**\n",
    "```plaintext\n",
    "RFE Selected Features: ['Age', 'Cart_Items', 'Discount_Code', 'Device_Type', 'Region']\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Interpretation of the Output**\n",
    "\n",
    "1. **Selected Features**:\n",
    "   - **'Age'**: RFE included `Age` in the top 5 features, possibly indicating it has some relevance in predicting the target (`Purchase`), even though it was not selected by forward or backward methods.\n",
    "   - **'Cart_Items'**: Consistently selected across all methods, suggesting it’s a strong predictor of `Purchase`.\n",
    "   - **'Discount_Code'**: Indicates the importance of discounts in influencing purchase behavior.\n",
    "   - **'Device_Type'**: Suggests that the type of device used (mobile, desktop, etc.) impacts purchasing decisions.\n",
    "   - **'Region'**: Location may play a role in predicting purchasing behavior.\n",
    "\n",
    "2. **Differences from Forward/Backward Selection**:\n",
    "   - **Addition of 'Age'**:\n",
    "     - Unlike forward or backward selection, RFE considers `Age` significant, likely due to how the logistic regression model evaluates its importance in combination with other features.\n",
    "   - The rest of the selected features are consistent with previous methods, highlighting their overall importance.\n",
    "\n",
    "3. **Strength of RFE**:\n",
    "   - RFE ranks features based on their contribution to the model’s predictive performance. It eliminates features iteratively, which might uncover features that interact with others, like `Age`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "- RFE selected 5 features: **'Age', 'Cart_Items', 'Discount_Code', 'Device_Type', 'Region'**.\n",
    "- While `Age` was not selected by forward or backward methods, RFE identified it as relevant, suggesting it may interact with other features to improve model performance.\n",
    "- The other 4 features align with forward and backward selection, confirming their strong predictive power.\n",
    "\n",
    "---\n",
    "\n",
    "### **Next Steps**\n",
    "1. **Model Validation**:\n",
    "   - Train the model using the RFE-selected features and compare performance metrics (e.g., accuracy, AUC-ROC) with those using forward and backward-selected features.\n",
    "2. **Feature Interaction**:\n",
    "   - Investigate possible interactions involving `Age` and other features to explain why RFE retained it.\n",
    "3. **Consensus Selection**:\n",
    "   - Combine insights from all three wrapper methods to finalize the optimal feature set for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f08803ad-282e-4c23-a15e-8ea5bc3b002e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Selection Features: ['Cart_Items', 'Discount_Code', 'Device_Type', 'Region']\n",
      "Backward Elimination Features: ['Cart_Items', 'Discount_Code', 'Device_Type', 'Region']\n",
      "RFE Selected Features: ['Age', 'Cart_Items', 'Discount_Code', 'Device_Type', 'Region']\n"
     ]
    }
   ],
   "source": [
    "# Display results from all methods\n",
    "print(\"Forward Selection Features:\", list(forward_selected_features))\n",
    "print(\"Backward Elimination Features:\", list(backward_selected_features))\n",
    "print(\"RFE Selected Features:\", list(rfe_selected_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b334704-97f4-46ce-85e0-ae3e379cca76",
   "metadata": {},
   "source": [
    "### **Inference from the Results**\n",
    "\n",
    "The output displays the selected features from three different wrapper methods: **Forward Selection**, **Backward Elimination**, and **Recursive Feature Elimination (RFE)**. Let’s analyze the results:\n",
    "\n",
    "---\n",
    "\n",
    "### **Results**\n",
    "1. **Forward Selection Features**:\n",
    "   - `['Cart_Items', 'Discount_Code', 'Device_Type', 'Region']`\n",
    "2. **Backward Elimination Features**:\n",
    "   - `['Cart_Items', 'Discount_Code', 'Device_Type', 'Region']`\n",
    "3. **RFE Selected Features**:\n",
    "   - `['Age', 'Cart_Items', 'Discount_Code', 'Device_Type', 'Region']`\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Observations**\n",
    "1. **Common Features**:\n",
    "   - `Cart_Items`, `Discount_Code`, `Device_Type`, and `Region` are consistently selected by **all three methods**.\n",
    "   - These features are likely the most important and relevant predictors of the target variable (`Purchase`).\n",
    "\n",
    "2. **Discrepancy in RFE**:\n",
    "   - RFE includes an additional feature: **`Age`**, which was not selected by forward or backward methods.\n",
    "   - This suggests that RFE identifies `Age` as contributing to the model’s performance, possibly due to interactions or relationships with other features.\n",
    "\n",
    "3. **Agreement Between Forward and Backward**:\n",
    "   - Forward Selection and Backward Elimination selected the exact same set of features, confirming the robustness of these methods in identifying the most critical predictors.\n",
    "\n",
    "4. **Ranking Insight from RFE**:\n",
    "   - While `Age` was not selected by forward or backward methods, its inclusion in RFE suggests it has some significance when considered along with other features.\n",
    "\n",
    "---\n",
    "\n",
    "### **Interpretation of Selected Features**\n",
    "- **`Cart_Items`**:\n",
    "  - The number of items in the cart is a strong predictor of whether a purchase will occur.\n",
    "- **`Discount_Code`**:\n",
    "  - The use of a discount code likely influences a customer’s decision to purchase.\n",
    "- **`Device_Type`**:\n",
    "  - The type of device (mobile, desktop, etc.) used for shopping may impact purchasing behavior.\n",
    "- **`Region`**:\n",
    "  - Geographic location might correlate with purchasing trends or behavior.\n",
    "- **`Age` (RFE)**:\n",
    "  - While not universally selected, `Age` could play a minor role, perhaps interacting with other features like `Cart_Items` or `Discount_Code`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Next Steps**\n",
    "1. **Model Evaluation**:\n",
    "   - Train and evaluate models using features selected by each method and compare performance metrics (e.g., accuracy, F1 score, AUC-ROC) to validate the selected feature sets.\n",
    "2. **Feature Engineering**:\n",
    "   - Investigate potential interactions involving `Age` (e.g., `Age * Cart_Items`) to understand why RFE identified it as important.\n",
    "3. **Final Feature Selection**:\n",
    "   - Consider combining the insights from all three methods to create a robust final feature set:\n",
    "     - Start with `Cart_Items`, `Discount_Code`, `Device_Type`, and `Region`.\n",
    "     - Optionally include `Age` based on validation results.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "The agreement between Forward Selection and Backward Elimination strongly validates the importance of `Cart_Items`, `Discount_Code`, `Device_Type`, and `Region`. The inclusion of `Age` by RFE highlights the need to further investigate its role, as it could hold value in specific contexts or interactions. These selected features can now be used for training a machine learning model with optimized performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f9f80c-5000-4f4c-a2d6-146e0a35324d",
   "metadata": {},
   "source": [
    "### Explanation of Results\n",
    "\n",
    "- Forward Selection:\n",
    "Provides the most critical subset of features, starting from no features and adding only those that improve model performance.\n",
    "\n",
    "- Backward Elimination:\n",
    "Provides a similar subset but starts with all features, removing the least important ones.\n",
    "\n",
    "- RFE:\n",
    "Uses a ranking mechanism to recursively remove the least important features. The final subset might differ slightly due to the recursive nature of the method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bcbfa9-fe3d-4549-a2a7-0185e2d842e1",
   "metadata": {},
   "source": [
    "### **Do Wrapper Methods Include Interaction Effects?**\n",
    "\n",
    "Yes, **wrapper methods** can include **interaction effects**, but this depends on the machine learning model used as the estimator in the wrapper method. Wrapper methods evaluate feature subsets based on the performance of a predictive model, and some models inherently consider interaction effects while others do not.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Points on Interaction Effects in Wrapper Methods**\n",
    "1. **What Are Interaction Effects?**\n",
    "   - Interaction effects occur when the relationship between one feature and the target variable depends on the value of another feature.\n",
    "   - Example: In an e-commerce context, the effect of a `Discount_Code` on purchase likelihood might vary depending on the `Device_Type`.\n",
    "\n",
    "2. **Wrapper Methods and Interaction Effects**:\n",
    "   - Wrapper methods rely on the underlying model (e.g., logistic regression, decision trees) to evaluate the performance of feature subsets. The ability to capture interaction effects depends on the model used:\n",
    "     - **Linear Models (e.g., Logistic Regression)**:\n",
    "       - Do **not automatically consider interactions** unless you explicitly include interaction terms in the feature set (e.g., `Discount_Code * Device_Type`).\n",
    "       - You need to engineer interaction features manually if using these models.\n",
    "     - **Tree-Based Models (e.g., Random Forest, XGBoost)**:\n",
    "       - Automatically capture interaction effects because they split data hierarchically and consider combinations of feature splits.\n",
    "       - For instance, a decision tree might split first on `Discount_Code` and then on `Device_Type`, inherently modeling the interaction between the two.\n",
    "\n",
    "3. **Recursive Feature Elimination (RFE)**:\n",
    "   - RFE with tree-based models can identify interaction effects because the model's feature importance reflects both individual and interaction contributions.\n",
    "   - With linear models, RFE cannot detect interaction effects unless interaction terms are explicitly included in the feature set.\n",
    "\n",
    "4. **Sequential Feature Selectors (Forward/Backward Selection)**:\n",
    "   - These methods evaluate subsets of features sequentially, but their ability to include interaction effects depends on the estimator:\n",
    "     - **Linear Models**: Require manual inclusion of interaction terms.\n",
    "     - **Tree-Based Models**: Automatically account for interactions during evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "### **How to Handle Interaction Effects in Wrapper Methods?**\n",
    "\n",
    "1. **If Using Linear Models**:\n",
    "   - Manually create interaction terms as part of the feature engineering process.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df['Discount_Device_Interaction'] = df['Discount_Code'] * df['Device_Type']\n",
    "     ```\n",
    "   - Include these interaction terms in the feature set for wrapper methods.\n",
    "\n",
    "2. **If Using Tree-Based Models**:\n",
    "   - Tree-based models like Random Forest and XGBoost inherently handle interaction effects, so no additional steps are needed.\n",
    "\n",
    "3. **Hybrid Approach**:\n",
    "   - Combine wrapper methods with feature engineering to test both individual features and interaction effects.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example**\n",
    "\n",
    "#### **With a Linear Model (Logistic Regression)**:\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Include interaction terms in the feature set\n",
    "X['Discount_Device_Interaction'] = X['Discount_Code'] * X['Device_Type']\n",
    "\n",
    "# Apply RFE\n",
    "model = LogisticRegression(max_iter=500)\n",
    "rfe_selector = RFE(estimator=model, n_features_to_select=5)\n",
    "rfe_selector.fit(X, y)\n",
    "\n",
    "# Selected Features\n",
    "print(\"Selected Features:\", X.columns[rfe_selector.support_])\n",
    "```\n",
    "\n",
    "#### **With a Tree-Based Model (Random Forest)**:\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Use Random Forest for RFE\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "rfe_selector = RFE(estimator=model, n_features_to_select=5)\n",
    "rfe_selector.fit(X, y)\n",
    "\n",
    "# Selected Features\n",
    "print(\"Selected Features:\", X.columns[rfe_selector.support_])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "- Wrapper methods **can include interaction effects** if the model used as an estimator supports them.\n",
    "- For **linear models**, interaction terms need to be manually engineered.\n",
    "- For **tree-based models**, interaction effects are inherently captured, making them more robust for complex feature relationships.\n",
    "- To fully capture interaction effects, it’s often best to use tree-based models in wrapper methods or explicitly engineer interactions for linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23febdf-4fcd-44d4-89b2-386df827f58d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
